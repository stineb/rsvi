---
title: "RSVI_v2"
author: "Paula and Beni"
date: "`r Sys.Date()`"
output:
  html_document:
    toc: true
    toc_float: true
    toc_depth: 2
# output:
#   pdf_document:
#     toc: true
#     toc_depth: 2
header-includes:
   - \usepackage{amsmath}
# bibliography: bibliography.bib
---

```{r}
source("MOD09_MODOC_filter.R")
source("remove_outliers.R")
source("gather_data.R")
source("wrap_ml.R")

library(dplyr)
library(lubridate)
library(readr)
library(ggplot2)
library(caret)
library(tidyverse)
library(yardstick)
library(recipes)
library(rbeni)
```

# Gather data

- Load data and trains a model (one for the regression, and one for the classification) with all available predictors.
Drought prediction: Run from line 115


## Gather data: site-specific CSV files downloaded by Adria

Function "MOD09_MODOC_filter" combines MOD09GA and MODOCGA products for all sites (one CSV for each FLUXNET site) into one. The output is a csv file o it is in "MOD09GA_MODOCGA_filter_indices.Rdata" file (for more information see README - "MODIS Data information")

```{r warning=FALSE, message=FALSE}
filn <- "./data/FLUXNET_MODOCGA_MOD09GA1km_2000_2018_processed.csv"

if (!file.exists(filn)){
  ## process original files
  ddf <- MOD09_MODOC_filter(dir_raw = "./data/FLUXNET_MODOCGA_MOD09GA1km_2000_2018/", QC500_filter = FALSE) %>% 
    rename(site = sites_id) %>% 
    mutate(date = ymd(paste(as.character(YY), as.character(MM), as.character(DD), sep="-")))
  write_csv(ddf, path = "./data/FLUXNET_MODOCGA_MOD09GA1km_2000_2018.csv")
  
  ddf <- read_csv("./data/FLUXNET_MODOCGA_MOD09GA1km_2000_2018.csv")
  
  # xxx this doesn't make sense ddf <- gather_data(ddf, add_scaled = FALSE, file="df") %>% ungroup()
  
  ## XXX Martina: WE DON'T NEED THAT ANYMORE (reduces to using only indices. We want to keep all spectral info)
  ## load processed data directly and get daily mean, normalised, etc.
  ddf <- gather_data("./data/FLUXNET_MODOCGA_MOD09GA1km_2000_2018.csv", add_scaled = FALSE) %>% 
    ungroup()
  
  # ddf <- gather_data("./data/MOD09GA_MODOCGA_filter_indices.Rdata", add_scaled = FALSE) %>% ungroup()
  
  write_csv(ddf, path = filn)
  
} else {
  
  ddf <- read_csv(filn)
  
}
```

## Site selection

Subset homogenous sites. Selection of sites is based on whether sites could be allocated to clusters in Stocker et al. (2018) and based on the selection by Manuela Balzarolo (see `site_selection_rsvi.Rmd`).
```{r}
df_homo <- read_csv("./data/sites2.csv")
ddf <- ddf %>% 
  dplyr::filter( site %in% df_homo$sitename )

# dovars <- c("cci", "evi", "ndvi", "NIRv", "pri")
# ddf <- ddf %>%
#   dplyr::select(site, date, one_of(dovars))
```


## Complement data

Add fLUE data.
```{r, eval = FALSE}
## Get fLUE Stocker et al., 2018 publicly available data here: https://zenodo.org/record/1158524#.W_bNMZNKjOQ
ddf <- read_csv("data/flue_stocker18nphyt.csv") %>% 
  dplyr::select(site, date, flue, is_flue_drought) %>%
  right_join(ddf, by=c("site", "date"))
# save(ddf, file = "./data/ddf_v5.Rdata")
```


Preprocessed data (subset for homogeneous sites, filtered by quality, merged with flue data and towres data)
```{r, eval = FALSE}
# Shortcut N2:
# load("./data/ddf_v5.Rdata")
# load("./data/metainfo_Tier1_sites_kgclimate_fluxnet2015.Rdata")
library(ingestr)  # to get site info
load("./data/obs_eval_NT.Rdata")
```

## Tidy data

Complement info using the meta info of FLUXNET sites provided through rsofun.
Includes temperature, APAR, and select only 5 vegetation classes. Clean database, no NA
```{r, eval = FALSE}
# Vegetation classes
cv <- c("ENF","DBF","GRA","EBF","SAV")

ddf_nn <- ddf %>%
  left_join(siteinfo_fluxnet2015 %>% dplyr::select(site=sitename, classid), by = "site") %>%
  left_join(dplyr::rename(obs_eval_NT$ddf, site=sitename), by=c("site", "date")) %>%
  mutate (APAR = ppfd_fluxnet2015 * fapar) %>%
  dplyr::filter(!is.na(flue)) %>%
  # dplyr::select(date, site, is_flue_drought, flue, all_of(dovars), APAR, temp, classid) %>%
  mutate(classid=factor(classid), is_flue_drought = factor(is_flue_drought)) %>%
  drop_na()

 # Subset ONLY 5 classes (cv)
ddf_nn$classid[ddf_nn$classid=="WSA"] <- "SAV"
ddf_sub <- ddf_nn %>%
  dplyr::filter(classid %in% cv) %>% 
  droplevels()

save(ddf_sub, file = "./data/ddf_sub.Rdata")
```

Predictors and data ready to train (ddf_sub)
```{r}
# Shortcut N3:
## XXX Martina: revise selection of predictors. Rather use separate spectral bands plus meteo data.
load("./data/ddf_sub.Rdata")
complete <- c("ndvi",    "evi",     "cci",     "pri",     "NIRv",    "APAR",  "temp",  "classid")
sites <- ddf_sub$site %>% unique()
```


# Drought classification

Predictions of drought or non-drought days.

## Single split (global model)

Must be split by site.
```{r}
set.seed(1982)
nsites_train <- 18
sites_train <- sample(sites, nsites_train)
df_train <- ddf_sub %>% 
  dplyr::filter(site %in% sites_train)
df_test <- ddf_sub %>% 
  dplyr::filter(!(site %in% sites_train))
```

Train model on a single training set and evaluate on the single testing set from the initial split
```{r, eval = TRUE}
filn <- "./results/modl_is_flue_drought_nnet_GLOBAL.Rdata"
if (!file.exists(filn)){
  modl <- wrap_ml( df = df_train,
                   nam_target = "is_flue_drought",
                   nam_group = "site",
                   method =  "nnet",
                   train_method = "myLGOCV",
                   predictors = complete,
                   tune = FALSE,
                   inner = FALSE,
                   classification = TRUE
                  )
  ## save model object
  save(modl, file = filn)

} else {
  load(filn)
}

df_test$pred <- predict(modl, newdata = df_test)

confusionMatrix(data = df_test$pred, reference = df_test$is_flue_drought)
postResample(pred = df_test$pred, obs = df_test$is_flue_drought)
```


## Leave-group-out split 

This is to assess the variance of evaluation metrics derived from test sets.
```{r, eval = TRUE}
filn <- "./results/modl_is_flue_drought_nnet_INNER.Rdata"
if (!file.exists(filn)){
  modl <- wrap_ml( df = ddf_sub,
                   nam_target = "is_flue_drought",
                   nam_group = "site",
                   method =  "nnet",
                   train_method = "myLGOCV",
                   predictors = complete,
                   tune = FALSE,
                   inner = TRUE,
                   classification = TRUE
                  )
  
  ## save model object (WARNING: IS A BIT BIG)
  save(modl, file = filn)
} else {
  load(filn)
}
```

Get evaluation results across left-out sites from inner loop.
```{r}
df_inner <- purrr::map(modl, "results") %>% 
  purrr::map_dbl("accuracy") %>% 
  stack() %>% 
  dplyr::select(site = ind, accuracy = values) %>% 
  left_join(
    purrr::map(modl, "results") %>% 
      purrr::map_dbl("kappa") %>% 
      stack() %>% 
      dplyr::select(site = ind, kappa = values),
    by = "site"
  )

df_inner %>% knitr::kable()

df_inner %>% 
  summarise(kappa_mean = mean(kappa), accuracy_mean = mean(accuracy),
            kappa_median = median(kappa), accuracy_median = median(accuracy),
            kappa_sd = sd(kappa), accuracy_sd = sd(accuracy)) %>% 
  knitr::kable()

gg1 <- df_inner %>% 
  ggplot(aes(x = kappa, y = ..count..)) +
  geom_histogram(bins = 5) +
  labs(title = "Kappa")

gg2 <- df_inner %>% 
  ggplot(aes(x = accuracy, y = ..count..)) +
  geom_histogram(bins = 5) +
  labs(title = "Accuracy")

library(patchwork)
gg2 + gg1
```

Combine predictions on test sets from the inner loop (on the single held-out site). This is the most relevant metric here!
```{r}
df_test_inner <- purrr::map_dfr(modl, "df_test")
confusionMatrix( data = df_test_inner$pred,
                 reference = df_test_inner$is_flue_drought, 
                 positive = "TRUE"
                 )
```

# Drought magnitude

Predictions of drought magnitude.

## Single split (global model)

Must be split by site.
```{r}
set.seed(1982)
nsites_train <- 18
sites_train <- sample(sites, nsites_train)
df_train <- ddf_sub %>% 
  dplyr::filter(site %in% sites_train)
df_test <- ddf_sub %>% 
  dplyr::filter(!(site %in% sites_train))
```

Train model on a single training set and evaluate on the single testing set from the initial split
```{r, eval = TRUE}
filn <- "./results/modl_flue_nnet_GLOBAL.Rdata"
if (!file.exists(filn)){
  modl <- wrap_ml( df = df_train,
                   nam_target = "flue",
                   nam_group = "site",
                   method =  "nnet",
                   train_method = "myLGOCV",
                   predictors = complete,
                   tune = TRUE,
                   inner = FALSE,
                   classification = FALSE
                  )
  ## save model object
  save(modl, file = filn)
} else {
  load(filn)
}
```


## Leave-group-out split 

This is to assess the variance of evaluation metrics derived from test sets.
```{r, eval = TRUE}
filn <- "./results/modl_flue_nnet_INNER.Rdata"
if (!file.exists(filn)){
  modl <- wrap_ml( df = ddf_sub,
                   nam_target = "flue",
                   nam_group = "site",
                   method =  "nnet",
                   train_method = "myLGOCV",
                   predictors = complete,
                   tune = FALSE,
                   inner = TRUE,
                   classification = FALSE
                  )
  
  ## save model object (WARNING: IS A BIT BIG)
  save(modl, file = filn)
} else {
  load(filn)
}
```

Get evaluation results across left-out sites from inner loop.
```{r}
df_inner <- purrr::map_dfr(modl, "results") %>% 
  pivot_wider(names_from = .metric, values_from = .estimate) %>% 
  dplyr::select(-.estimator)

df_inner %>% knitr::kable()

df_inner %>% 
  summarise(rmse_mean = mean(rmse), rsq_mean = mean(rsq),
            rmse_median = median(rmse), rsq_median = median(rsq),
            rmse_sd = sd(rmse), rsq_sd = sd(rsq)) %>% 
  knitr::kable()

gg1 <- df_inner %>% 
  ggplot(aes(x = rmse, y = ..count..)) +
  geom_histogram(bins = 5) +
  labs(title = "RMSE")

gg2 <- df_inner %>% 
  ggplot(aes(x = rsq, y = ..count..)) +
  geom_histogram(bins = 5) +
  labs(title = expression(italic(R)^2))

gg2 + gg1
```

Combine predictions on test sets from the inner loop (on the single held-out site). This is the most relevant metric here!
```{r}
df_test_inner <- purrr::map_dfr(modl, "df_test")

df_test_inner %>% 
  rbeni::analyse_modobs2("pred", "flue", type = "heat")
```



<!-- ## Example: Time series (mod-obs) -->
<!-- ```{r} -->
<!-- #### One Site time series: ### -->
<!-- sitename <- "FR-Pue" -->
<!-- one <- list_modobs_listmodels$`FR-Pue` -->
<!-- ts_one <- ddf %>% filter(site == sitename ) %>% left_join(rename(one, flue=obs), by="flue") %>% -->
<!--   select(site, date, flue, is_flue_drought, mod) -->

<!-- library(reshape2) -->
<!-- ts <- melt(ts_one,id.vars = c("site","date","is_flue_drought"), measure.vars = c("flue", "mod") ) -->
<!-- print(ggplot(ts, aes(x=date, y=value, group=variable)) + -->
<!--         geom_line(aes(color=variable)) + -->
<!--         scale_color_manual(values=c("black","red"), -->
<!--                            name = NULL, labels = c("Observed fLUE","Predicted fLUE")) + -->
<!--         theme_classic() + ggtitle(sitename)  + -->
<!--         labs(x="Date", y="Unitless") + -->
<!--         theme(axis.text=element_text(size=12, color="black"), -->
<!--               axis.title=element_text(size=14), -->
<!--               panel.border = element_rect(colour = "black", fill=NA)) + -->
<!--         scale_x_date(limits = as.Date(c('2000-01-01','2015-01-01'))) + labs(x="Date")) -->

<!-- ``` -->